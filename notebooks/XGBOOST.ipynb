{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "15ef9e4a-ae3a-45fe-a7a3-05850ef59f11",
   "metadata": {},
   "source": [
    "# Data Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7d07c82a-fb58-401a-9562-f6b2080b4f5d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Read data\n",
    "import pandas as pd\n",
    "merged_df = pd.read_csv('../data/processed/merged_df.csv',low_memory=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "45c995c2-3a54-4c70-9cdb-11ca286dfb9f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_df=merged_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1caec60c-6732-4d42-921f-7da6b9c65712",
   "metadata": {},
   "source": [
    "# Reduce the size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d6605135-0567-49f3-ae8d-7e5464fab074",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Memory Usage: 28997.45 MB\n",
      "Reduced Memory Usage: 1261.80 MB\n",
      "Memory Reduced by: 95.65%\n"
     ]
    }
   ],
   "source": [
    "# fill missing values\n",
    "# Fill missing values in 'column 1' and 'column 2' with 0\n",
    "train_df['sell_price'].fillna(0, inplace=True)\n",
    "train_df['revenue'].fillna(0, inplace=True)\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "class MemoryReducer:\n",
    "    def __init__(self, df):\n",
    "        self.df = df.copy()\n",
    "\n",
    "    def reduce_memory_usage(self):\n",
    "        initial_memory = self.df.memory_usage(deep=True).sum() / (1024 ** 2)  # in megabytes\n",
    "        print(f\"Initial Memory Usage: {initial_memory:.2f} MB\")\n",
    "\n",
    "        for col in self.df.columns:\n",
    "            col_type = self.df[col].dtype\n",
    "\n",
    "            if col_type != object:\n",
    "                if \"int\" in str(col_type):\n",
    "                    self.df[col] = pd.to_numeric(self.df[col], downcast=\"integer\")\n",
    "                elif \"float\" in str(col_type):\n",
    "                    self.df[col] = pd.to_numeric(self.df[col], downcast=\"float\")\n",
    "            else:\n",
    "                num_unique_values = len(self.df[col].unique())\n",
    "                num_total_values = len(self.df[col])\n",
    "                if num_unique_values / num_total_values < 0.5:\n",
    "                    self.df[col] = self.df[col].astype(\"category\")\n",
    "\n",
    "        reduced_memory = self.df.memory_usage(deep=True).sum() / (1024 ** 2)  # in megabytes\n",
    "        print(f\"Reduced Memory Usage: {reduced_memory:.2f} MB\")\n",
    "        reduction_percentage = ((initial_memory - reduced_memory) / initial_memory) * 100\n",
    "        print(f\"Memory Reduced by: {reduction_percentage:.2f}%\")\n",
    "\n",
    "        return self.df\n",
    "\n",
    "\n",
    "\n",
    "reducer = MemoryReducer(train_df)\n",
    "reduced_df = reducer.reduce_memory_usage()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9a02a4e8-f81a-419f-86e1-9c679c7d419a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#rename\n",
    "df_train=reduced_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2672c9eb-fd6b-4eda-937c-1d201fefa6fc",
   "metadata": {},
   "source": [
    "# Load and Explore Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3d393de1-d043-454d-9bab-70fa8c008e40",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>dept_id</th>\n",
       "      <th>cat_id</th>\n",
       "      <th>store_id</th>\n",
       "      <th>state_id</th>\n",
       "      <th>day</th>\n",
       "      <th>count</th>\n",
       "      <th>date</th>\n",
       "      <th>wm_yr_wk</th>\n",
       "      <th>event_name</th>\n",
       "      <th>event_type</th>\n",
       "      <th>sell_price</th>\n",
       "      <th>revenue</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HOBBIES_1_001_CA_1_evaluation</td>\n",
       "      <td>HOBBIES_1_001</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>2011-01-29</td>\n",
       "      <td>11101</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2011</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HOBBIES_1_002_CA_1_evaluation</td>\n",
       "      <td>HOBBIES_1_002</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>2011-01-29</td>\n",
       "      <td>11101</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2011</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HOBBIES_1_003_CA_1_evaluation</td>\n",
       "      <td>HOBBIES_1_003</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>2011-01-29</td>\n",
       "      <td>11101</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2011</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HOBBIES_1_004_CA_1_evaluation</td>\n",
       "      <td>HOBBIES_1_004</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>2011-01-29</td>\n",
       "      <td>11101</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2011</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HOBBIES_1_005_CA_1_evaluation</td>\n",
       "      <td>HOBBIES_1_005</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>2011-01-29</td>\n",
       "      <td>11101</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2011</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              id        item_id    dept_id   cat_id store_id   \n",
       "0  HOBBIES_1_001_CA_1_evaluation  HOBBIES_1_001  HOBBIES_1  HOBBIES     CA_1  \\\n",
       "1  HOBBIES_1_002_CA_1_evaluation  HOBBIES_1_002  HOBBIES_1  HOBBIES     CA_1   \n",
       "2  HOBBIES_1_003_CA_1_evaluation  HOBBIES_1_003  HOBBIES_1  HOBBIES     CA_1   \n",
       "3  HOBBIES_1_004_CA_1_evaluation  HOBBIES_1_004  HOBBIES_1  HOBBIES     CA_1   \n",
       "4  HOBBIES_1_005_CA_1_evaluation  HOBBIES_1_005  HOBBIES_1  HOBBIES     CA_1   \n",
       "\n",
       "  state_id  day  count        date  wm_yr_wk event_name event_type   \n",
       "0       CA   29      0  2011-01-29     11101          0          0  \\\n",
       "1       CA   29      0  2011-01-29     11101          0          0   \n",
       "2       CA   29      0  2011-01-29     11101          0          0   \n",
       "3       CA   29      0  2011-01-29     11101          0          0   \n",
       "4       CA   29      0  2011-01-29     11101          0          0   \n",
       "\n",
       "   sell_price  revenue  year  month  \n",
       "0         0.0      0.0  2011      1  \n",
       "1         0.0      0.0  2011      1  \n",
       "2         0.0      0.0  2011      1  \n",
       "3         0.0      0.0  2011      1  \n",
       "4         0.0      0.0  2011      1  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#see the head\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2da2639a-1594-4e2e-b507-35c9d8b680ed",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(47107050, 16)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#see the dimension\n",
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b5e33e3d-81f1-4b98-8ef7-56debb0bf047",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 47107050 entries, 0 to 47107049\n",
      "Data columns (total 16 columns):\n",
      " #   Column      Dtype   \n",
      "---  ------      -----   \n",
      " 0   id          category\n",
      " 1   item_id     category\n",
      " 2   dept_id     category\n",
      " 3   cat_id      category\n",
      " 4   store_id    category\n",
      " 5   state_id    category\n",
      " 6   day         int8    \n",
      " 7   count       int16   \n",
      " 8   date        category\n",
      " 9   wm_yr_wk    int16   \n",
      " 10  event_name  category\n",
      " 11  event_type  category\n",
      " 12  sell_price  float32 \n",
      " 13  revenue     float32 \n",
      " 14  year        int16   \n",
      " 15  month       int8    \n",
      "dtypes: category(9), float32(2), int16(3), int8(2)\n",
      "memory usage: 1.2 GB\n"
     ]
    }
   ],
   "source": [
    "#see the info\n",
    "df_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2642d770-d95e-47b9-82cb-0e5ad960ba75",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2011 2012 2013 2014 2015]\n"
     ]
    }
   ],
   "source": [
    "# Assuming you have a DataFrame called df\n",
    "unique_year_values = df_train['year'].unique()\n",
    "\n",
    "# This will give you an array of unique values in the 'yar' column\n",
    "print(unique_year_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "18247698-8627-4d4b-a594-0ca12c4cbaa1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique values in 'id': 30490\n"
     ]
    }
   ],
   "source": [
    "# Count unique values in 'id'\n",
    "unique_count_id = df_train['id'].nunique()\n",
    "\n",
    "print(f\"Number of unique values in 'id': {unique_count_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4d0b6e61-8f7f-4cd2-92a7-9b64a8351348",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique values in 'item_id': 3049\n"
     ]
    }
   ],
   "source": [
    "# Count unique values in 'item_id'\n",
    "unique_count_item_id = df_train['item_id'].nunique()\n",
    "\n",
    "print(f\"Number of unique values in 'item_id': {unique_count_item_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "977297a5-fd67-4ef2-80d9-7aad72a2f04b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique values in 'dept_id': 7\n"
     ]
    }
   ],
   "source": [
    "# Count unique values in 'dept_id'\n",
    "unique_count_dept_id = df_train['dept_id'].nunique()\n",
    "\n",
    "print(f\"Number of unique values in 'dept_id': {unique_count_dept_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "14da62b4-b6ef-4419-b153-d5d519b0859e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique values in 'store_id': 10\n"
     ]
    }
   ],
   "source": [
    "# Count unique values in 'store_id'\n",
    "unique_count_store_id = df_train['store_id'].nunique()\n",
    "\n",
    "print(f\"Number of unique values in 'store_id': {unique_count_store_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "76d4e26a-e9de-431c-b796-f74eb9f2e7a3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique values in 'state_id': 3\n"
     ]
    }
   ],
   "source": [
    "# Count unique values in 'state_id'\n",
    "unique_count_state_id = df_train['state_id'].nunique()\n",
    "\n",
    "print(f\"Number of unique values in 'state_id': {unique_count_state_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c68c216-39ed-449a-b415-dade8c3b89eb",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "675e34f0-02f9-4274-ae7b-fca56ab46326",
   "metadata": {},
   "source": [
    "we use binary encoding for those with categorical columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "97aaac9d-5dd1-4455-9f45-eff3760c4f84",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import category_encoders as ce\n",
    "\n",
    "\n",
    "# Create a BinaryEncoder instance\n",
    "encoder = ce.BinaryEncoder(cols=['item_id','event_type', 'event_name','dept_id', 'cat_id', 'store_id','state_id'])\n",
    "\n",
    "# Fit and transform the DataFrame to perform binary encoding\n",
    "df_encoded = encoder.fit_transform(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "33a92c36-09b8-4869-b298-863f2a2918a8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#rename_df\n",
    "df_train=df_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bc46ab9f-f530-4c02-ba4e-ddd4e1cd3c9a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# fill missing values\n",
    "# Fill missing values in 'column 1' and 'column 2' with 0\n",
    "df_train['sell_price'].fillna(0, inplace=True)\n",
    "df_train['revenue'].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1e01da31-83d8-4ec0-a192-190d791b403e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'item_id_0', 'item_id_1', 'item_id_2', 'item_id_3', 'item_id_4',\n",
       "       'item_id_5', 'item_id_6', 'item_id_7', 'item_id_8', 'item_id_9',\n",
       "       'item_id_10', 'item_id_11', 'dept_id_0', 'dept_id_1', 'dept_id_2',\n",
       "       'cat_id_0', 'cat_id_1', 'store_id_0', 'store_id_1', 'store_id_2',\n",
       "       'store_id_3', 'state_id_0', 'state_id_1', 'day', 'count', 'date',\n",
       "       'wm_yr_wk', 'event_name_0', 'event_name_1', 'event_name_2',\n",
       "       'event_name_3', 'event_name_4', 'event_type_0', 'event_type_1',\n",
       "       'event_type_2', 'sell_price', 'revenue', 'year', 'month'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#see the columns\n",
    "df_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "efd2f1ab-f1f4-4c97-8602-f9c3d8af6c64",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# drop 'wm_yr_wk' column\n",
    "df_train.drop(columns=['wm_yr_wk'], inplace=True)\n",
    "\n",
    "# drop 'date' column\n",
    "df_train.drop(columns=['date'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b93a4484-b731-45ac-a9f3-1004fc4ab0be",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 47107050 entries, 0 to 47107049\n",
      "Data columns (total 38 columns):\n",
      " #   Column        Dtype   \n",
      "---  ------        -----   \n",
      " 0   id            category\n",
      " 1   item_id_0     int64   \n",
      " 2   item_id_1     int64   \n",
      " 3   item_id_2     int64   \n",
      " 4   item_id_3     int64   \n",
      " 5   item_id_4     int64   \n",
      " 6   item_id_5     int64   \n",
      " 7   item_id_6     int64   \n",
      " 8   item_id_7     int64   \n",
      " 9   item_id_8     int64   \n",
      " 10  item_id_9     int64   \n",
      " 11  item_id_10    int64   \n",
      " 12  item_id_11    int64   \n",
      " 13  dept_id_0     int64   \n",
      " 14  dept_id_1     int64   \n",
      " 15  dept_id_2     int64   \n",
      " 16  cat_id_0      int64   \n",
      " 17  cat_id_1      int64   \n",
      " 18  store_id_0    int64   \n",
      " 19  store_id_1    int64   \n",
      " 20  store_id_2    int64   \n",
      " 21  store_id_3    int64   \n",
      " 22  state_id_0    int64   \n",
      " 23  state_id_1    int64   \n",
      " 24  day           int8    \n",
      " 25  count         int16   \n",
      " 26  event_name_0  int64   \n",
      " 27  event_name_1  int64   \n",
      " 28  event_name_2  int64   \n",
      " 29  event_name_3  int64   \n",
      " 30  event_name_4  int64   \n",
      " 31  event_type_0  int64   \n",
      " 32  event_type_1  int64   \n",
      " 33  event_type_2  int64   \n",
      " 34  sell_price    float32 \n",
      " 35  revenue       float32 \n",
      " 36  year          int16   \n",
      " 37  month         int8    \n",
      "dtypes: category(1), float32(2), int16(2), int64(31), int8(2)\n",
      "memory usage: 11.6 GB\n"
     ]
    }
   ],
   "source": [
    "#get info\n",
    "df_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "96d0b954-fd4f-4032-ba98-d8c04691012d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#calculating lags feature\n",
    "import numpy as np\n",
    "def calculate_lagged_values(df, lags, column_name):\n",
    "    for lag in lags:\n",
    "        df[column_name + \"_lag_\" + str(lag)] = df.groupby(\"id\")[column_name].shift(lag).astype(np.float16)\n",
    "        df[column_name + \"_lag_\" + str(lag)].fillna(0, inplace=True)\n",
    "\n",
    "lags=[1,5,7,14]\n",
    "calculate_lagged_values(df_train, lags, \"revenue\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f415d0f-bf76-4655-bb15-9515527d5fbb",
   "metadata": {},
   "source": [
    "In summary, calculating lags is a way to look at past sales data to see if it has any influence on the sales made on the current day. It helps you explore whether there's a relationship between recent sales and today's sales in a store."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "63db8a73-c27a-4f1b-863e-34b6e454ae1e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#drop id column\n",
    "df_train.drop(columns=['id'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "207993c0-8d16-4290-81dd-cef97b332593",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 47107050 entries, 0 to 47107049\n",
      "Data columns (total 41 columns):\n",
      " #   Column          Dtype  \n",
      "---  ------          -----  \n",
      " 0   item_id_0       int64  \n",
      " 1   item_id_1       int64  \n",
      " 2   item_id_2       int64  \n",
      " 3   item_id_3       int64  \n",
      " 4   item_id_4       int64  \n",
      " 5   item_id_5       int64  \n",
      " 6   item_id_6       int64  \n",
      " 7   item_id_7       int64  \n",
      " 8   item_id_8       int64  \n",
      " 9   item_id_9       int64  \n",
      " 10  item_id_10      int64  \n",
      " 11  item_id_11      int64  \n",
      " 12  dept_id_0       int64  \n",
      " 13  dept_id_1       int64  \n",
      " 14  dept_id_2       int64  \n",
      " 15  cat_id_0        int64  \n",
      " 16  cat_id_1        int64  \n",
      " 17  store_id_0      int64  \n",
      " 18  store_id_1      int64  \n",
      " 19  store_id_2      int64  \n",
      " 20  store_id_3      int64  \n",
      " 21  state_id_0      int64  \n",
      " 22  state_id_1      int64  \n",
      " 23  day             int8   \n",
      " 24  count           int16  \n",
      " 25  event_name_0    int64  \n",
      " 26  event_name_1    int64  \n",
      " 27  event_name_2    int64  \n",
      " 28  event_name_3    int64  \n",
      " 29  event_name_4    int64  \n",
      " 30  event_type_0    int64  \n",
      " 31  event_type_1    int64  \n",
      " 32  event_type_2    int64  \n",
      " 33  sell_price      float32\n",
      " 34  revenue         float32\n",
      " 35  year            int16  \n",
      " 36  month           int8   \n",
      " 37  revenue_lag_1   float16\n",
      " 38  revenue_lag_5   float16\n",
      " 39  revenue_lag_7   float16\n",
      " 40  revenue_lag_14  float16\n",
      "dtypes: float16(4), float32(2), int16(2), int64(31), int8(2)\n",
      "memory usage: 11.8 GB\n"
     ]
    }
   ],
   "source": [
    "df_train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06f5f458-9fe4-4a8e-b2e7-dada9df56790",
   "metadata": {},
   "source": [
    "we only use subset of dataset since the dataset is huge and our kernel died everytime trying to use whole dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c1eaa348-6a0f-49f9-bb7f-b018c2959efd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#subset of data\n",
    "unique_years = df_train['year'].unique()\n",
    "sampled_data = []\n",
    "\n",
    "for year in unique_years:\n",
    "    year_subset = df_train[df_train['year'] == year]\n",
    "    sample_size = len(year_subset) // 10  # 1/10th of data for each year\n",
    "    if sample_size > 0:\n",
    "        sampled_year_data = year_subset.sample(n=sample_size, random_state=42)  # Randomly sample data for the year\n",
    "        sampled_data.append(sampled_year_data)\n",
    "\n",
    "# Combine the sampled data from each year into a new DataFrame\n",
    "sampled_dataset = pd.concat(sampled_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4a08942c-0d23-4f0e-bd79-8a396845f12a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 4710705 entries, 6623485 to 45200367\n",
      "Data columns (total 41 columns):\n",
      " #   Column          Dtype  \n",
      "---  ------          -----  \n",
      " 0   item_id_0       int64  \n",
      " 1   item_id_1       int64  \n",
      " 2   item_id_2       int64  \n",
      " 3   item_id_3       int64  \n",
      " 4   item_id_4       int64  \n",
      " 5   item_id_5       int64  \n",
      " 6   item_id_6       int64  \n",
      " 7   item_id_7       int64  \n",
      " 8   item_id_8       int64  \n",
      " 9   item_id_9       int64  \n",
      " 10  item_id_10      int64  \n",
      " 11  item_id_11      int64  \n",
      " 12  dept_id_0       int64  \n",
      " 13  dept_id_1       int64  \n",
      " 14  dept_id_2       int64  \n",
      " 15  cat_id_0        int64  \n",
      " 16  cat_id_1        int64  \n",
      " 17  store_id_0      int64  \n",
      " 18  store_id_1      int64  \n",
      " 19  store_id_2      int64  \n",
      " 20  store_id_3      int64  \n",
      " 21  state_id_0      int64  \n",
      " 22  state_id_1      int64  \n",
      " 23  day             int8   \n",
      " 24  count           int16  \n",
      " 25  event_name_0    int64  \n",
      " 26  event_name_1    int64  \n",
      " 27  event_name_2    int64  \n",
      " 28  event_name_3    int64  \n",
      " 29  event_name_4    int64  \n",
      " 30  event_type_0    int64  \n",
      " 31  event_type_1    int64  \n",
      " 32  event_type_2    int64  \n",
      " 33  sell_price      float32\n",
      " 34  revenue         float32\n",
      " 35  year            int16  \n",
      " 36  month           int8   \n",
      " 37  revenue_lag_1   float16\n",
      " 38  revenue_lag_5   float16\n",
      " 39  revenue_lag_7   float16\n",
      " 40  revenue_lag_14  float16\n",
      "dtypes: float16(4), float32(2), int16(2), int64(31), int8(2)\n",
      "memory usage: 1.2 GB\n"
     ]
    }
   ],
   "source": [
    "sampled_dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a6985e2e-a568-4f45-81b4-029675c65dec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4710705, 41)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampled_dataset.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa4d450b-6c8b-4381-aa5a-be5c696bea67",
   "metadata": {},
   "source": [
    "# Split dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e7f9d6cb-feaf-49cd-b78f-46ebe5d74a8b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# indicating x and y columns \n",
    "y= sampled_dataset[\"revenue\"]\n",
    "x= sampled_dataset.drop([\"revenue\"],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f329c8c5-549c-4543-bbaa-6cc2313b67ec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#split dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "#Split the dataset into 2 different sets: data (80%) and test (20%)\n",
    "x_data, x_test, y_data, y_test = train_test_split(x,y, test_size=0.2, random_state=42)\n",
    "\n",
    "#Split the data randomly into 2 different sets: training (80%) and validation (20%)\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_data, y_data, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd0f62e5-e05a-4556-af91-3b9e6506447e",
   "metadata": {},
   "source": [
    "# Scale the dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "74b3e845-d6c6-4cbc-9cb5-3f0db8da1fd5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler \n",
    "#Replace the feature values wirh rhe result of the scaler\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(x_train)\n",
    "X_test_scaled = scaler.transform(x_test)\n",
    "X_val_scaled = scaler.transform(x_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4e38fee-529c-40cf-a3e5-758935772d49",
   "metadata": {},
   "source": [
    "# ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3a6c02e8-67bb-42be-8d46-7fd9c785b981",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n",
      "[CV] END .......................gamma=0.05, n_estimators=650; total time=  16.4s\n",
      "[CV] END .......................gamma=0.05, n_estimators=650; total time=  16.2s\n",
      "[CV] END .......................gamma=0.05, n_estimators=650; total time=  16.8s\n",
      "[CV] END .......................gamma=0.05, n_estimators=650; total time=  16.5s\n",
      "[CV] END .......................gamma=0.05, n_estimators=650; total time=  17.1s\n",
      "[CV] END ........................gamma=0.5, n_estimators=650; total time=  12.9s\n",
      "[CV] END ........................gamma=0.5, n_estimators=650; total time=  12.9s\n",
      "[CV] END ........................gamma=0.5, n_estimators=650; total time=  12.8s\n",
      "[CV] END ........................gamma=0.5, n_estimators=650; total time=  12.4s\n",
      "[CV] END ........................gamma=0.5, n_estimators=650; total time=  12.9s\n",
      "[CV] END ..........................gamma=1, n_estimators=650; total time=  11.7s\n",
      "[CV] END ..........................gamma=1, n_estimators=650; total time=  11.7s\n",
      "[CV] END ..........................gamma=1, n_estimators=650; total time=  11.6s\n",
      "[CV] END ..........................gamma=1, n_estimators=650; total time=  12.0s\n",
      "[CV] END ..........................gamma=1, n_estimators=650; total time=  11.8s\n",
      "Best hyperparameters: {'gamma': 0.05, 'n_estimators': 650}\n",
      "Root Mean Squared Error (RMSE): 0.092370264\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.model_selection import GridSearchCV, KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "# Initialize XGBoost regressor\n",
    "xgb_regressor = xgb.XGBRegressor()\n",
    "\n",
    "param_dist = {\n",
    "    \"n_estimators\": [250, 350, 450,650 ],\n",
    "     #\"max_depth\": range(15, 20, 1),\n",
    "     \"gamma\": [0.05, 0.5,1],\n",
    "    # \"learning_rate\": [0.1, 0.2, 0.3]\n",
    "}\n",
    "\n",
    "# Scale your features using StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_scaled)\n",
    "\n",
    "# Define cross-validation strategy (e.g., KFold)\n",
    "cv = KFold(n_splits=5, shuffle=True, random_state=42) \n",
    "\n",
    "# Use GridSearchCV to find the best hyperparameters\n",
    "grid = GridSearchCV(\n",
    "    xgb_regressor, param_dist, cv=cv, refit=True, scoring='neg_mean_squared_error', verbose=2\n",
    ")\n",
    "grid.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Print the best hyperparameters found\n",
    "print(\"Best hyperparameters:\", grid.best_params_)\n",
    "\n",
    "# Get the best model\n",
    "best_model = grid.best_estimator_\n",
    "\n",
    "# Predict on the validation set\n",
    "y_pred = best_model.predict(X_train_scaled)\n",
    "\n",
    "# Calculate RMSE\n",
    "rmse = np.sqrt(mean_squared_error(y_train, y_pred))\n",
    "print(\"Root Mean Squared Error (RMSE):\", rmse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b1b8c77d-54d3-4bda-8f20-a21dde6edcce",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error Test (RMSE): 0.3576363\n"
     ]
    }
   ],
   "source": [
    "# Predict on the validation set\n",
    "y_pred_test = best_model.predict(X_test_scaled)\n",
    "\n",
    "# Calculate RMSE\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred_test))\n",
    "print(\"Root Mean Squared Error Test (RMSE):\", rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de70c3ab-71c0-4999-8dc7-695eff400da1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
