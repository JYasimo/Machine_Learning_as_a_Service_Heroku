{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "ce68ceb0-64a1-4bc2-a3db-273a0d82852f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# libraries\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, OrdinalEncoder\n",
    "from sklearn.linear_model import SGDClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9ea5655-e477-457c-86fd-a43c8f57feaf",
   "metadata": {
    "tags": []
   },
   "source": [
    "# load dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "1cf17a2b-7912-4f65-a1ec-0a9af3ad8c20",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Read data\n",
    "import pandas as pd\n",
    "merged_df = pd.read_csv('../data/processed/merged_df.csv',low_memory=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 510,
   "id": "925ef4bb-e44a-40f4-ae1d-68c10908f4e5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_df=merged_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28c7db50-143e-4780-b5ae-f7a22381aaae",
   "metadata": {},
   "source": [
    "# reduce size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5137c89-fb13-407d-bfd7-51125b0f79fc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "class MemoryReducer:\n",
    "    def __init__(self, df):\n",
    "        self.df = df.copy()\n",
    "\n",
    "    def reduce_memory_usage(self):\n",
    "        initial_memory = self.df.memory_usage(deep=True).sum() / (1024 ** 2)  # in megabytes\n",
    "        print(f\"Initial Memory Usage: {initial_memory:.2f} MB\")\n",
    "\n",
    "        for col in self.df.columns:\n",
    "            col_type = self.df[col].dtype\n",
    "\n",
    "            if col_type != object:\n",
    "                if \"int\" in str(col_type):\n",
    "                    self.df[col] = pd.to_numeric(self.df[col], downcast=\"integer\")\n",
    "                elif \"float\" in str(col_type):\n",
    "                    self.df[col] = pd.to_numeric(self.df[col], downcast=\"float\")\n",
    "            else:\n",
    "                num_unique_values = len(self.df[col].unique())\n",
    "                num_total_values = len(self.df[col])\n",
    "                if num_unique_values / num_total_values < 0.5:\n",
    "                    self.df[col] = self.df[col].astype(\"category\")\n",
    "\n",
    "        reduced_memory = self.df.memory_usage(deep=True).sum() / (1024 ** 2)  # in megabytes\n",
    "        print(f\"Reduced Memory Usage: {reduced_memory:.2f} MB\")\n",
    "        reduction_percentage = ((initial_memory - reduced_memory) / initial_memory) * 100\n",
    "        print(f\"Memory Reduced by: {reduction_percentage:.2f}%\")\n",
    "\n",
    "        return self.df\n",
    "\n",
    "\n",
    "\n",
    "reducer = MemoryReducer(train_df)\n",
    "reduced_df = reducer.reduce_memory_usage()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aea8f22-25aa-46ff-9682-0cb85eac93f9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_train=reduced_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad36c30d-1944-41f3-b944-f12c565b362f",
   "metadata": {
    "tags": []
   },
   "source": [
    "# PipeLine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f99fa259-bb90-43f2-abd3-15f88f3c65b2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import category_encoders as ce\n",
    "import numpy as np\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "\n",
    "# Create a BinaryEncoder instance\n",
    "encoder = ce.BinaryEncoder(cols=['event_type', 'event_name'])\n",
    "\n",
    "# Define a custom transformer to fill missing values\n",
    "def fill_missing_values(X):\n",
    "    X['sell_price'].fillna(0, inplace=True)\n",
    "    X['revenue'].fillna(0, inplace=True)\n",
    "    return X\n",
    "\n",
    "\n",
    "# Define a custom transformer to calculate lags features\n",
    "def calculate_lags(X):\n",
    "    lags = [1, 2, 3, 5, 7, 14, 30]\n",
    "    for lag in lags:\n",
    "        X[\"lag_\" + str(lag)] = X.groupby(\"id\")[\"revenue\"].shift(lag).astype(np.float16)\n",
    "    \n",
    "    # Fill NaN values with 0 in the lag columns\n",
    "    lag_columns = [col for col in X.columns if col.startswith(\"lag_\")]\n",
    "    X[lag_columns] = X[lag_columns].fillna(0)\n",
    "\n",
    "    # Remove the 'id' column\n",
    "    X = X.drop(columns=['id'])\n",
    "\n",
    "    return X\n",
    "\n",
    "\n",
    "# Define a custom transformer to remove columns\n",
    "def remove_columns(X):\n",
    "    return X.drop(columns=['date','wm_yr_wk'])\n",
    "\n",
    "\n",
    "# Create a ColumnTransformer to apply transformers to specific columns\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('binary_encoder', encoder, ['event_type', 'event_name']),\n",
    "        ('fill_missing', FunctionTransformer(fill_missing_values, validate=False), ['sell_price', 'revenue']),\n",
    "        ('calculate_lags', FunctionTransformer(calculate_lags, validate=False), ['revenue', 'id']),\n",
    "        ('remove_columns', FunctionTransformer(remove_columns, validate=False), ['date', 'wm_yr_wk'])\n",
    "    ],\n",
    "    remainder='passthrough'  # Pass through the columns not mentioned above\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# Create a pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    #('scaler', StandardScaler())  # Optionally, you can add a scaler if needed\n",
    "])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e687bc2e-9705-4af2-a754-624df1aff828",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# Separate the features and the target variable\n",
    "y = df_train['revenue']\n",
    "X = df_train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbd3d444-dc7e-476c-be35-ee2d13822420",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# List of column names to be treated as categorical features\n",
    "categorical_columns = ['id','item_id', 'dept_id', 'cat_id', 'store_id']\n",
    "\n",
    "# Create a LightGBM regressor with your desired parameters\n",
    "lgb_regressor = lgb.LGBMRegressor(\n",
    "    n_estimators=450,\n",
    "    random_state=42,\n",
    "    categorical_feature=categorical_columns  # Specify categorical features here\n",
    ")\n",
    "\n",
    "# Create the pipeline\n",
    "lgb_pipe = Pipeline(\n",
    "    steps=[\n",
    "        ('preprocessor', preprocessor),  # Assuming you have a preprocessor step\n",
    "        ('lgb_regressor', lgb_regressor)  # Add LightGBM regressor as a step\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac8677a4-ccc7-4df0-8dfe-c55791737c03",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "random_sample = df_train.sample(n=3000, random_state=42)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5081dad-eefc-4de1-860a-f4c73dfb4a0e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "# Assuming you have a DataFrame called random_sample and 'Target' is your regression target\n",
    "\n",
    "target = random_sample['revenue']  # Regression target\n",
    "\n",
    "# Create and fit the pip\n",
    "transform=lgb_pipe.fit(random_sample, target)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "273a8d8b-80af-4f18-8757-a6745289d95b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Fit and transform the pipeline on your input data\n",
    "transformed_data = pipeline.transform(random_sample)\n",
    "\n",
    "# Convert the transformed data into a DataFrame (if it's not already)\n",
    "# This assumes you're using pandas for data manipulation\n",
    "import pandas as pd\n",
    "transformed_df = pd.DataFrame(transformed_data)\n",
    "\n",
    "# View the head of the transformed DataFrame\n",
    "transformed_df.sample(20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "id": "907a317d-5f58-4089-b196-d970018d6f42",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>HOBBIES_1_293</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12.74</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>HOUSEHOLD_1_351</td>\n",
       "      <td>HOUSEHOLD_1</td>\n",
       "      <td>HOUSEHOLD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>FOODS_3_047</td>\n",
       "      <td>FOODS_3</td>\n",
       "      <td>FOODS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.52</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>FOODS_3_689</td>\n",
       "      <td>FOODS_3</td>\n",
       "      <td>FOODS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>HOUSEHOLD_2_206</td>\n",
       "      <td>HOUSEHOLD_2</td>\n",
       "      <td>HOUSEHOLD</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      10   11   12   13   14   15   16   17               18           19   \n",
       "0    0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0    HOBBIES_1_293    HOBBIES_1  \\\n",
       "1  12.74  0.0  0.0  0.0  0.0  0.0  0.0  0.0  HOUSEHOLD_1_351  HOUSEHOLD_1   \n",
       "2    NaN  0.0  0.0  0.0  0.0  0.0  0.0  0.0      FOODS_3_047      FOODS_3   \n",
       "3  11.52  0.0  0.0  0.0  0.0  0.0  0.0  0.0      FOODS_3_689      FOODS_3   \n",
       "4    0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  HOUSEHOLD_2_206  HOUSEHOLD_2   \n",
       "\n",
       "          20  \n",
       "0    HOBBIES  \n",
       "1  HOUSEHOLD  \n",
       "2      FOODS  \n",
       "3      FOODS  \n",
       "4  HOUSEHOLD  "
      ]
     },
     "execution_count": 509,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Assuming df is your DataFrame\n",
    "selected_columns = transformed_df.iloc[:, 10:21]  # Select columns 10 to 20 (inclusive) - Python uses 0-based indexing\n",
    "selected_columns.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1c02a8b-6ced-41bd-959e-685a89e49e4f",
   "metadata": {},
   "source": [
    "Note:\n",
    "\n",
    "filling missing values âœ…\n",
    "\n",
    "lags produce Nan ðŸš«\n",
    "\n",
    "mean roll produce Nan (get rid of it)\n",
    "\n",
    "remove âœ…"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edf447b7-7f7c-4ff6-b708-e7c6d989af32",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
